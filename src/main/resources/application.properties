spring.application.name=kafka-consumer-example

server.port=9292


#spring.kafka.consumer.bootstrap-servers=localhost:9092
#spring.kafka.consumer.client-id=sj-consumer-group
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
## This package name should be same as it is in the producer
#spring.kafka.consumer.properties.spring.json.trusted.packages=com.kafka.producer.dto

# single logging file name
logging.file.name=logs/live.log

# Filename pattern for creating log archives
logging.logback.rollingpolicy.file-name-pattern=logs/data-share-%d{yyyy-MM-dd}.%i.log

# Clean up old log archives when the application starts (true/false)
logging.logback.rollingpolicy.clean-history-on-start=true

# Maximum size of a log file before it is archived
logging.logback.rollingpolicy.max-file-size=1MB

# Maximum size of all archived log files combined
logging.logback.rollingpolicy.total-size-cap=2GB

# Maximum number of archived log files to keep
logging.logback.rollingpolicy.max-history=2048